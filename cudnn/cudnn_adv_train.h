/*
 * Copyright 2014-2023 NVIDIA Corporation.  All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee.  Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE.  IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users.  These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item.  Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/*   cudnn_adv_train : cuDNN's advanced and experimental features.

*/

#if !defined(CUDNN_ADV_TRAIN_H_)
#define CUDNN_ADV_TRAIN_H_

#include <sycl/sycl.hpp>
#include <dpct/dpct.hpp>
#include <stdint.h>

#include "cudnn_version.h"
#include "cudnn_ops_infer.h"
#include "cudnn_ops_train.h"
#include "cudnn_adv_infer.h"

/* These version numbers are autogenerated, do not edit manually. */
#define CUDNN_ADV_TRAIN_MAJOR 8
#define CUDNN_ADV_TRAIN_MINOR 9
#define CUDNN_ADV_TRAIN_PATCH 1

#if (CUDNN_ADV_TRAIN_MAJOR != CUDNN_MAJOR) || (CUDNN_ADV_TRAIN_MINOR != CUDNN_MINOR) || \
    (CUDNN_ADV_TRAIN_PATCH != CUDNN_PATCHLEVEL)
#error Version mismatch in cuDNN ADV TRAIN!!!
#endif

#if defined(__cplusplus)
extern "C" {
#endif

typedef enum {
    CUDNN_WGRAD_MODE_ADD = 0, /* add partial gradients to wgrad output buffers */
    CUDNN_WGRAD_MODE_SET = 1, /* write partial gradients to wgrad output buffers */
} cudnnWgradMode_t;

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnRNNForwardTraining(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const int seqLength, const dpct::dnnl::memory_desc_ext *xDesc,
    const void *x, const dpct::dnnl::memory_desc_ext hxDesc, const void *hx,
    const dpct::dnnl::memory_desc_ext cxDesc, const void *cx,
    const dpct::dnnl::memory_desc_ext wDesc, const void *w,
    const dpct::dnnl::memory_desc_ext *yDesc, void *y,
    const dpct::dnnl::memory_desc_ext hyDesc, void *hy,
    const dpct::dnnl::memory_desc_ext cyDesc, void *cy, void *workSpace,
    size_t workSpaceSizeInBytes, void *reserveSpace,
    size_t reserveSpaceSizeInBytes);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnRNNBackwardData(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const int seqLength, const dpct::dnnl::memory_desc_ext *yDesc,
    const void *y, const dpct::dnnl::memory_desc_ext *dyDesc, const void *dy,
    const dpct::dnnl::memory_desc_ext dhyDesc, const void *dhy,
    const dpct::dnnl::memory_desc_ext dcyDesc, const void *dcy,
    const dpct::dnnl::memory_desc_ext wDesc, const void *w,
    const dpct::dnnl::memory_desc_ext hxDesc, const void *hx,
    const dpct::dnnl::memory_desc_ext cxDesc, const void *cx,
    const dpct::dnnl::memory_desc_ext *dxDesc, void *dx,
    const dpct::dnnl::memory_desc_ext dhxDesc, void *dhx,
    const dpct::dnnl::memory_desc_ext dcxDesc, void *dcx, void *workSpace,
    size_t workSpaceSizeInBytes, void *reserveSpace,
    size_t reserveSpaceSizeInBytes);

dpct::err1 CUDNNWINAPI cudnnRNNBackwardData_v8(
    dpct::dnnl::engine_ext handle, dpct::dnnl::rnn_desc rnnDesc,
    const int32_t devSeqLengths[], dpct::dnnl::memory_desc_ext yDesc,
    const void *y, const void *dy, dpct::dnnl::memory_desc_ext xDesc, void *dx,
    dpct::dnnl::memory_desc_ext hDesc, const void *hx, const void *dhy,
    void *dhx, dpct::dnnl::memory_desc_ext cDesc, const void *cx,
    const void *dcy, void *dcx, size_t weightSpaceSize, const void *weightSpace,
    size_t workSpaceSize, void *workSpace, size_t reserveSpaceSize,
    void *reserveSpace);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnRNNBackwardWeights(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const int seqLength, const dpct::dnnl::memory_desc_ext *xDesc,
    const void *x, const dpct::dnnl::memory_desc_ext hxDesc, const void *hx,
    const dpct::dnnl::memory_desc_ext *yDesc, const void *y,
    const void *workSpace, size_t workSpaceSizeInBytes,
    const dpct::dnnl::memory_desc_ext dwDesc, void *dw,
    const void *reserveSpace, size_t reserveSpaceSizeInBytes);

dpct::err1 CUDNNWINAPI cudnnRNNBackwardWeights_v8(
    dpct::dnnl::engine_ext handle, dpct::dnnl::rnn_desc rnnDesc,
    cudnnWgradMode_t addGrad, const int32_t devSeqLengths[],
    dpct::dnnl::memory_desc_ext xDesc, const void *x,
    dpct::dnnl::memory_desc_ext hDesc, const void *hx,
    dpct::dnnl::memory_desc_ext yDesc, const void *y, size_t weightSpaceSize,
    void *dweightSpace, size_t workSpaceSize, void *workSpace,
    size_t reserveSpaceSize, void *reserveSpace);

/* RNN EX API */

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnRNNForwardTrainingEx(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const dpct::dnnl::memory_desc_ext xDesc, const void *x,
    const dpct::dnnl::memory_desc_ext hxDesc, const void *hx,
    const dpct::dnnl::memory_desc_ext cxDesc, const void *cx,
    const dpct::dnnl::memory_desc_ext wDesc, const void *w,
    const dpct::dnnl::memory_desc_ext yDesc, void *y,
    const dpct::dnnl::memory_desc_ext hyDesc, void *hy,
    const dpct::dnnl::memory_desc_ext cyDesc, void *cy,
    const dpct::dnnl::memory_desc_ext kDesc, /* reserved, should pass NULL */
    const void *keys,                        /* reserved, should pass NULL */
    const dpct::dnnl::memory_desc_ext cDesc, /* reserved, should pass NULL */
    void *cAttn,                             /* reserved, should pass NULL */
    const dpct::dnnl::memory_desc_ext iDesc, /* reserved, should pass NULL */
    void *iAttn,                             /* reserved, should pass NULL */
    const dpct::dnnl::memory_desc_ext qDesc, /* reserved, should pass NULL */
    void *queries,                           /* reserved, should pass NULL */
    void *workSpace, size_t workSpaceSizeInBytes, void *reserveSpace,
    size_t reserveSpaceSizeInBytes);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnRNNBackwardDataEx(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const dpct::dnnl::memory_desc_ext yDesc, const void *y,
    const dpct::dnnl::memory_desc_ext dyDesc, const void *dy,
    const dpct::dnnl::memory_desc_ext dcDesc, /* reserved, should pass NULL */
    const void *dcAttn,                       /* reserved, should pass NULL */
    const dpct::dnnl::memory_desc_ext dhyDesc, const void *dhy,
    const dpct::dnnl::memory_desc_ext dcyDesc, const void *dcy,
    const dpct::dnnl::memory_desc_ext wDesc, const void *w,
    const dpct::dnnl::memory_desc_ext hxDesc, const void *hx,
    const dpct::dnnl::memory_desc_ext cxDesc, const void *cx,
    const dpct::dnnl::memory_desc_ext dxDesc, void *dx,
    const dpct::dnnl::memory_desc_ext dhxDesc, void *dhx,
    const dpct::dnnl::memory_desc_ext dcxDesc, void *dcx,
    const dpct::dnnl::memory_desc_ext dkDesc, /* reserved, should pass NULL */
    void *dkeys,                              /* reserved, should pass NULL */
    void *workSpace, size_t workSpaceSizeInBytes, void *reserveSpace,
    size_t reserveSpaceSizeInBytes);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnRNNBackwardWeightsEx(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const dpct::dnnl::memory_desc_ext xDesc, const void *x,
    const dpct::dnnl::memory_desc_ext hxDesc, const void *hx,
    const dpct::dnnl::memory_desc_ext yDesc, const void *y, void *workSpace,
    size_t workSpaceSizeInBytes, const dpct::dnnl::memory_desc_ext dwDesc,
    void *dw, void *reserveSpace, size_t reserveSpaceSizeInBytes);

/* RNN FIND API */

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI
cudnnGetRNNForwardTrainingAlgorithmMaxCount(dpct::dnnl::engine_ext handle,
                                            const dpct::dnnl::rnn_desc rnnDesc,
                                            int *count);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnFindRNNForwardTrainingAlgorithmEx(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const int seqLength, const dpct::dnnl::memory_desc_ext *xDesc,
    const void *x, const dpct::dnnl::memory_desc_ext hxDesc, const void *hx,
    const dpct::dnnl::memory_desc_ext cxDesc, const void *cx,
    const dpct::dnnl::memory_desc_ext wDesc, const void *w,
    const dpct::dnnl::memory_desc_ext *yDesc, void *y,
    const dpct::dnnl::memory_desc_ext hyDesc, void *hy,
    const dpct::dnnl::memory_desc_ext cyDesc, void *cy,
    const float findIntensity, const int requestedAlgoCount,
    int *returnedAlgoCount, cudnnAlgorithmPerformance_t *perfResults,
    void *workspace, size_t workSpaceSizeInBytes, void *reserveSpace,
    size_t reserveSpaceSizeInBytes);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI
cudnnGetRNNBackwardDataAlgorithmMaxCount(dpct::dnnl::engine_ext handle,
                                         const dpct::dnnl::rnn_desc rnnDesc,
                                         int *count);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnFindRNNBackwardDataAlgorithmEx(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const int seqLength, const dpct::dnnl::memory_desc_ext *yDesc,
    const void *y, const dpct::dnnl::memory_desc_ext *dyDesc, const void *dy,
    const dpct::dnnl::memory_desc_ext dhyDesc, const void *dhy,
    const dpct::dnnl::memory_desc_ext dcyDesc, const void *dcy,
    const dpct::dnnl::memory_desc_ext wDesc, const void *w,
    const dpct::dnnl::memory_desc_ext hxDesc, const void *hx,
    const dpct::dnnl::memory_desc_ext cxDesc, const void *cx,
    const dpct::dnnl::memory_desc_ext *dxDesc, void *dx,
    const dpct::dnnl::memory_desc_ext dhxDesc, void *dhx,
    const dpct::dnnl::memory_desc_ext dcxDesc, void *dcx,
    const float findIntensity, const int requestedAlgoCount,
    int *returnedAlgoCount, cudnnAlgorithmPerformance_t *perfResults,
    void *workspace, size_t workSpaceSizeInBytes, void *reserveSpace,
    size_t reserveSpaceSizeInBytes);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI
cudnnGetRNNBackwardWeightsAlgorithmMaxCount(dpct::dnnl::engine_ext handle,
                                            const dpct::dnnl::rnn_desc rnnDesc,
                                            int *count);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnFindRNNBackwardWeightsAlgorithmEx(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const int seqLength, const dpct::dnnl::memory_desc_ext *xDesc,
    const void *x, const dpct::dnnl::memory_desc_ext hxDesc, const void *hx,
    const dpct::dnnl::memory_desc_ext *yDesc, const void *y,
    const float findIntensity, const int requestedAlgoCount,
    int *returnedAlgoCount, cudnnAlgorithmPerformance_t *perfResults,
    const void *workspace, size_t workSpaceSizeInBytes,
    const dpct::dnnl::memory_desc_ext dwDesc, void *dw,
    const void *reserveSpace, size_t reserveSpaceSizeInBytes);

dpct::err1 CUDNNWINAPI cudnnMultiHeadAttnBackwardData(
    dpct::dnnl::engine_ext handle, const cudnnAttnDescriptor_t attnDesc,
    const int loWinIdx[], const int hiWinIdx[], const int devSeqLengthsDQDO[],
    const int devSeqLengthsDKDV[], const cudnnSeqDataDescriptor_t doDesc,
    const void *dout, const cudnnSeqDataDescriptor_t dqDesc, void *dqueries,
    const void *queries, const cudnnSeqDataDescriptor_t dkDesc, void *dkeys,
    const void *keys, const cudnnSeqDataDescriptor_t dvDesc, void *dvalues,
    const void *values, size_t weightSizeInBytes, const void *weights,
    size_t workSpaceSizeInBytes, void *workSpace,
    size_t reserveSpaceSizeInBytes, void *reserveSpace);

dpct::err1 CUDNNWINAPI cudnnMultiHeadAttnBackwardWeights(
    dpct::dnnl::engine_ext handle, const cudnnAttnDescriptor_t attnDesc,
    cudnnWgradMode_t addGrad, const cudnnSeqDataDescriptor_t qDesc,
    const void *queries, const cudnnSeqDataDescriptor_t kDesc, const void *keys,
    const cudnnSeqDataDescriptor_t vDesc, const void *values,
    const cudnnSeqDataDescriptor_t doDesc, const void *dout,
    size_t weightSizeInBytes, const void *weights, void *dweights,
    size_t workSpaceSizeInBytes, void *workSpace,
    size_t reserveSpaceSizeInBytes, void *reserveSpace);

/*
* CTC (Connectionist Temporal Classification) loss descriptor create/destory/set/get functions
*/
/* Input normalization mode for loss function */
typedef enum {
    CUDNN_LOSS_NORMALIZATION_NONE    = 0,
    CUDNN_LOSS_NORMALIZATION_SOFTMAX = 1,
} cudnnLossNormalizationMode_t;

dpct::err1 CUDNNWINAPI
cudnnCreateCTCLossDescriptor(cudnnCTCLossDescriptor_t *ctcLossDesc);

dpct::err1 CUDNNWINAPI cudnnSetCTCLossDescriptor(
    cudnnCTCLossDescriptor_t ctcLossDesc, dpct::library_data_t compType);

dpct::err1 CUDNNWINAPI cudnnSetCTCLossDescriptorEx(
    cudnnCTCLossDescriptor_t ctcLossDesc, dpct::library_data_t compType,
    cudnnLossNormalizationMode_t normMode,
    /*
    DPCT1082:24: Migration of cudnnNanPropagation_t type is not supported.
    */
    cudnnNanPropagation_t gradMode);

dpct::err1 CUDNNWINAPI cudnnSetCTCLossDescriptor_v8(
    cudnnCTCLossDescriptor_t ctcLossDesc, dpct::library_data_t compType,
    cudnnLossNormalizationMode_t normMode,
    /*
    DPCT1082:25: Migration of cudnnNanPropagation_t type is not supported.
    */
    cudnnNanPropagation_t gradMode, int maxLabelLength);

dpct::err1 CUDNNWINAPI cudnnGetCTCLossDescriptor(
    cudnnCTCLossDescriptor_t ctcLossDesc, dpct::library_data_t *compType);

dpct::err1 CUDNNWINAPI cudnnGetCTCLossDescriptorEx(
    cudnnCTCLossDescriptor_t ctcLossDesc, dpct::library_data_t *compType,
    cudnnLossNormalizationMode_t *normMode,
    /*
    DPCT1082:26: Migration of cudnnNanPropagation_t type is not supported.
    */
    cudnnNanPropagation_t *gradMode);

dpct::err1 CUDNNWINAPI cudnnGetCTCLossDescriptor_v8(
    cudnnCTCLossDescriptor_t ctcLossDesc, dpct::library_data_t *compType,
    cudnnLossNormalizationMode_t *normMode,
    /*
    DPCT1082:27: Migration of cudnnNanPropagation_t type is not supported.
    */
    cudnnNanPropagation_t *gradMode, int *maxLabelLength);

dpct::err1 CUDNNWINAPI
cudnnDestroyCTCLossDescriptor(cudnnCTCLossDescriptor_t ctcLossDesc);

/* return the ctc costs and gradients, given the probabilities and labels */
dpct::err1 CUDNNWINAPI cudnnCTCLoss(
    dpct::dnnl::engine_ext handle,
    const dpct::dnnl::memory_desc_ext
        probsDesc, /* Tensor descriptor for probabilities, the dimensions are
                      T,N,A (T is the timing steps, N is the mini batch size, A
                      is the alphabet size)  */
    const void *probs,      /* probabilities after softmax, in GPU memory */
    const int hostLabels[], /* labels, in CPU memory */
    const int hostLabelLengths[], /* the length of each label, in CPU memory */
    const int hostInputLengths[], /* the lengths of timing steps in each batch,
                                     in CPU memory */
    void *costs,                  /* the returned costs of CTC, in GPU memory */
    const dpct::dnnl::memory_desc_ext
        gradientsDesc, /* Tensor descriptor for gradients, the dimensions are
                          T,N,A */
    void *gradients,   /* the returned CTC gradients, in GPU memory, to compute
                          costs only, set it to NULL */
    cudnnCTCLossAlgo_t algo, /* algorithm selected, supported now 0 and 1 */
    cudnnCTCLossDescriptor_t ctcLossDesc,
    void *workspace,              /* pointer to the workspace, in GPU memory */
    size_t workSpaceSizeInBytes); /* size of the workspace */

/* return the ctc costs and gradients, given the probabilities and labels */
dpct::err1 CUDNNWINAPI cudnnCTCLoss_v8(
    dpct::dnnl::engine_ext handle,
    cudnnCTCLossAlgo_t algo, /* algorithm selected, supported now 0 and 1 */
    cudnnCTCLossDescriptor_t ctcLossDesc,
    const dpct::dnnl::memory_desc_ext
        probsDesc, /* Tensor descriptor for probabilities, the dimensions are
                      T,N,A (T is the timing steps, N is the mini batch size, A
                      is the alphabet size)  */
    const void *probs,        /* probabilities after softmax, in GPU memory */
    const int labels[],       /* labels, in GPU memory */
    const int labelLengths[], /* the length of each label, in GPU memory */
    const int inputLengths[], /* the lengths of timing steps in each batch, in
                                 GPU memory */
    void *costs,              /* the returned costs of CTC, in GPU memory */
    const dpct::dnnl::memory_desc_ext
        gradientsDesc, /* Tensor descriptor for gradients, the dimensions are
                          T,N,A */
    void *gradients,   /* the returned CTC gradients, in GPU memory, to compute
                          costs only, set it to NULL */
    size_t workSpaceSizeInBytes, /* size of the workspace */
    void *workspace);            /* pointer to the workspace, in GPU memory */

/* return the workspace size needed for ctc */
dpct::err1 CUDNNWINAPI cudnnGetCTCLossWorkspaceSize(
    dpct::dnnl::engine_ext handle,
    const dpct::dnnl::memory_desc_ext
        probsDesc, /* Tensor descriptor for probabilities, the dimensions are
                  T,N,A (T is the timing steps, N is the mini batch size, A is
                  the alphabet size) */
    const dpct::dnnl::memory_desc_ext
        gradientsDesc,       /* Tensor descriptor for gradients, the
                            dimensions are T,N,A. To compute costs
                            only, set it to NULL */
    const int *labels,       /* labels, in CPU memory */
    const int *labelLengths, /* the length of each label, in CPU memory */
    const int *inputLengths, /* the lengths of timing steps in each batch, in
                                CPU memory */
    cudnnCTCLossAlgo_t algo, /* algorithm selected, supported now 0 and 1 */
    cudnnCTCLossDescriptor_t ctcLossDesc,
    size_t *sizeInBytes); /* pointer to the returned workspace size */

/* return the workspace size needed for ctc */
dpct::err1 CUDNNWINAPI cudnnGetCTCLossWorkspaceSize_v8(
    dpct::dnnl::engine_ext handle,
    cudnnCTCLossAlgo_t algo, /* algorithm selected, supported now 0 and 1 */
    cudnnCTCLossDescriptor_t ctcLossDesc,
    const dpct::dnnl::memory_desc_ext
        probsDesc, /* Tensor descriptor for probabilities, the dimensions are
                  T,N,A (T is the timing steps, N is the mini batch size, A is
                  the alphabet size) */
    const dpct::dnnl::memory_desc_ext
        gradientsDesc,    /* Tensor descriptor for gradients, the
                         dimensions are T,N,A. To compute costs
                         only, set it to NULL */
    size_t *sizeInBytes); /* pointer to the returned workspace size */

/*
 * \brief Cross-library version checker.
 * This function is implemented differently in each sub-library. Each sublib
 * checks whether its own version matches that of its dependencies.
 * \returns CUDNN_STATUS_SUCCESS if the version check passes,
 *          CUDNN_STATUS_VERSION_MISMATCH if the versions are inconsistent.
 */
dpct::err1 CUDNNWINAPI cudnnAdvTrainVersionCheck(void);

#if defined(__cplusplus)
}
#endif

#endif /* CUDNN_ADV_TRAIN_H_ */
