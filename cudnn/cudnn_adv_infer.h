/*
 * Copyright 2014-2023 NVIDIA Corporation.  All rights reserved.
 *
 * NOTICE TO LICENSEE:
 *
 * This source code and/or documentation ("Licensed Deliverables") are
 * subject to NVIDIA intellectual property rights under U.S. and
 * international Copyright laws.
 *
 * These Licensed Deliverables contained herein is PROPRIETARY and
 * CONFIDENTIAL to NVIDIA and is being provided under the terms and
 * conditions of a form of NVIDIA software license agreement by and
 * between NVIDIA and Licensee ("License Agreement") or electronically
 * accepted by Licensee.  Notwithstanding any terms or conditions to
 * the contrary in the License Agreement, reproduction or disclosure
 * of the Licensed Deliverables to any third party without the express
 * written consent of NVIDIA is prohibited.
 *
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, NVIDIA MAKES NO REPRESENTATION ABOUT THE
 * SUITABILITY OF THESE LICENSED DELIVERABLES FOR ANY PURPOSE.  IT IS
 * PROVIDED "AS IS" WITHOUT EXPRESS OR IMPLIED WARRANTY OF ANY KIND.
 * NVIDIA DISCLAIMS ALL WARRANTIES WITH REGARD TO THESE LICENSED
 * DELIVERABLES, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY,
 * NONINFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.
 * NOTWITHSTANDING ANY TERMS OR CONDITIONS TO THE CONTRARY IN THE
 * LICENSE AGREEMENT, IN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY
 * SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, OR ANY
 * DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,
 * WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS
 * ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE
 * OF THESE LICENSED DELIVERABLES.
 *
 * U.S. Government End Users.  These Licensed Deliverables are a
 * "commercial item" as that term is defined at 48 C.F.R. 2.101 (OCT
 * 1995), consisting of "commercial computer software" and "commercial
 * computer software documentation" as such terms are used in 48
 * C.F.R. 12.212 (SEPT 1995) and is provided to the U.S. Government
 * only as a commercial end item.  Consistent with 48 C.F.R.12.212 and
 * 48 C.F.R. 227.7202-1 through 227.7202-4 (JUNE 1995), all
 * U.S. Government End Users acquire the Licensed Deliverables with
 * only those rights set forth herein.
 *
 * Any use of the Licensed Deliverables in individual and commercial
 * software must include, in the user documentation and internal
 * comments to the code, the above Disclaimer and U.S. Government End
 * Users Notice.
 */

/*   cudnn_adv_infer : cuDNN's advanced and experimental features.

*/

#if !defined(CUDNN_ADV_INFER_H_)
#define CUDNN_ADV_INFER_H_

#include <sycl/sycl.hpp>
#include <dpct/dpct.hpp>
#include <stdint.h>

#include "cudnn_version.h"
#include "cudnn_ops_infer.h"

/* These version numbers are autogenerated, do not edit manually. */
#define CUDNN_ADV_INFER_MAJOR 8
#define CUDNN_ADV_INFER_MINOR 9
#define CUDNN_ADV_INFER_PATCH 1

#if (CUDNN_ADV_INFER_MAJOR != CUDNN_MAJOR) || (CUDNN_ADV_INFER_MINOR != CUDNN_MINOR) || \
    (CUDNN_ADV_INFER_PATCH != CUDNN_PATCHLEVEL)
#error Version mismatch in cuDNN ADV INFER!!!
#endif

#if defined(__cplusplus)
extern "C" {
#endif

/* BASIC RNN API */

typedef enum {
    CUDNN_FWD_MODE_INFERENCE = 0,
    CUDNN_FWD_MODE_TRAINING  = 1,
} cudnnForwardMode_t;

typedef enum {
    CUDNN_RNN_RELU = 0, /* basic RNN cell type with ReLu activation */
    CUDNN_RNN_TANH = 1, /* basic RNN cell type with tanh activation */
    CUDNN_LSTM     = 2, /* LSTM with optional recurrent projection and clipping */
    CUDNN_GRU      = 3, /* Using h' = tanh(r * Uh(t-1) + Wx) and h = (1 - z) * h' + z * h(t-1); */
} cudnnRNNMode_t;

typedef enum {
    CUDNN_RNN_NO_BIAS         = 0, /* rnn cell formulas do not use biases */
    CUDNN_RNN_SINGLE_INP_BIAS = 1, /* rnn cell formulas use one input bias in input GEMM */
    CUDNN_RNN_DOUBLE_BIAS     = 2, /* default, rnn cell formulas use two bias vectors */
    CUDNN_RNN_SINGLE_REC_BIAS = 3  /* rnn cell formulas use one recurrent bias in recurrent GEMM */
} cudnnRNNBiasMode_t;

typedef enum {
    CUDNN_UNIDIRECTIONAL = 0, /* single direction network */
    CUDNN_BIDIRECTIONAL  = 1, /* output concatination at each layer */
} cudnnDirectionMode_t;

typedef enum {
    CUDNN_LINEAR_INPUT = 0, /* adjustable weight matrix in first layer input GEMM */
    CUDNN_SKIP_INPUT   = 1, /* fixed identity matrix in the first layer input GEMM */
} cudnnRNNInputMode_t;

typedef enum {
    CUDNN_RNN_CLIP_NONE   = 0, /* disables LSTM cell clipping */
    CUDNN_RNN_CLIP_MINMAX = 1, /* enables LSTM cell clipping */
} cudnnRNNClipMode_t;

typedef enum {
    CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_UNPACKED   = 0, /* padded, outer stride from one time-step to the next */
    CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_PACKED     = 1, /* sequence length sorted and packed as in basic RNN api */
    CUDNN_RNN_DATA_LAYOUT_BATCH_MAJOR_UNPACKED = 2, /* padded, outer stride from one batch to the next */
} cudnnRNNDataLayout_t;

/* Legacy type for backward compatibility */
typedef unsigned cudnnRNNPaddingMode_t;

/* For auxFlags in cudnnSetRNNDescriptor_v8() and cudnnSetRNNPaddingMode() */
#define CUDNN_RNN_PADDED_IO_DISABLED 0
#define CUDNN_RNN_PADDED_IO_ENABLED (1U << 0)

struct cudnnRNNStruct;
typedef struct cudnnRNNStruct *cudnnRNNDescriptor_t;

struct cudnnPersistentRNNPlan;
typedef struct cudnnPersistentRNNPlan *cudnnPersistentRNNPlan_t;

struct cudnnRNNDataStruct;
typedef struct cudnnRNNDataStruct *cudnnRNNDataDescriptor_t;

dpct::err1 CUDNNWINAPI cudnnCreateRNNDescriptor(dpct::dnnl::rnn_desc *rnnDesc);

dpct::err1 CUDNNWINAPI cudnnDestroyRNNDescriptor(dpct::dnnl::rnn_desc rnnDesc);

dpct::err1 CUDNNWINAPI cudnnSetRNNDescriptor_v8(
    dpct::dnnl::rnn_desc rnnDesc, cudnnRNNAlgo_t algo,
    dpct::dnnl::rnn_mode cellMode, dpct::dnnl::rnn_bias_mode biasMode,
    dpct::dnnl::rnn_direction dirMode, cudnnRNNInputMode_t inputMode,
    dpct::library_data_t dataType, dpct::library_data_t mathPrec,
    cudnnMathType_t mathType, int32_t inputSize, int32_t hiddenSize,
    int32_t projSize, int32_t numLayers, cudnnDropoutDescriptor_t dropoutDesc,
    uint32_t auxFlags);

dpct::err1 CUDNNWINAPI cudnnGetRNNDescriptor_v8(
    dpct::dnnl::rnn_desc rnnDesc, cudnnRNNAlgo_t *algo,
    dpct::dnnl::rnn_mode *cellMode, dpct::dnnl::rnn_bias_mode *biasMode,
    dpct::dnnl::rnn_direction *dirMode, cudnnRNNInputMode_t *inputMode,
    dpct::library_data_t *dataType, dpct::library_data_t *mathPrec,
    cudnnMathType_t *mathType, int32_t *inputSize, int32_t *hiddenSize,
    int32_t *projSize, int32_t *numLayers,
    cudnnDropoutDescriptor_t *dropoutDesc, uint32_t *auxFlags);

/*
 * mathPrec in cudnnSetRNNDescriptor_v6() specifies compute precision
 * compute precision is further modified by cudnnSetRNNMatrixMathType()
 * dataType in cudnnGetRNNParamsSize() and wDesc specify weight storage
 * dropout is between RNN layers, not between recurrent steps
 */
CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnSetRNNDescriptor_v6(
    dpct::dnnl::engine_ext handle, dpct::dnnl::rnn_desc rnnDesc,
    const int hiddenSize, const int numLayers,
    cudnnDropoutDescriptor_t dropoutDesc, cudnnRNNInputMode_t inputMode,
    dpct::dnnl::rnn_direction direction, dpct::dnnl::rnn_mode cellMode,
    cudnnRNNAlgo_t algo, dpct::library_data_t mathPrec);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnGetRNNDescriptor_v6(
    dpct::dnnl::engine_ext handle, dpct::dnnl::rnn_desc rnnDesc,
    int *hiddenSize, int *numLayers, cudnnDropoutDescriptor_t *dropoutDesc,
    cudnnRNNInputMode_t *inputMode, dpct::dnnl::rnn_direction *direction,
    dpct::dnnl::rnn_mode *cellMode, cudnnRNNAlgo_t *algo,
    dpct::library_data_t *mathPrec);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI
cudnnSetRNNMatrixMathType(dpct::dnnl::rnn_desc rnnDesc, cudnnMathType_t mType);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI
cudnnGetRNNMatrixMathType(dpct::dnnl::rnn_desc rnnDesc, cudnnMathType_t *mType);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnSetRNNBiasMode(
    dpct::dnnl::rnn_desc rnnDesc, dpct::dnnl::rnn_bias_mode biasMode);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnGetRNNBiasMode(
    dpct::dnnl::rnn_desc rnnDesc, dpct::dnnl::rnn_bias_mode *biasMode);

dpct::err1 CUDNNWINAPI cudnnRNNSetClip_v8(
    dpct::dnnl::rnn_desc rnnDesc, cudnnRNNClipMode_t clipMode,
    /*
    DPCT1082:20: Migration of cudnnNanPropagation_t type is not supported.
    */
    cudnnNanPropagation_t clipNanOpt, double lclip, double rclip);

dpct::err1 CUDNNWINAPI cudnnRNNGetClip_v8(
    dpct::dnnl::rnn_desc rnnDesc, cudnnRNNClipMode_t *clipMode,
    /*
    DPCT1082:21: Migration of cudnnNanPropagation_t type is not supported.
    */
    cudnnNanPropagation_t *clipNanOpt, double *lclip, double *rclip);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnRNNSetClip(
    dpct::dnnl::engine_ext handle, dpct::dnnl::rnn_desc rnnDesc,
    cudnnRNNClipMode_t clipMode,
    /*
    DPCT1082:22: Migration of cudnnNanPropagation_t type is not supported.
    */
    cudnnNanPropagation_t clipNanOpt, double lclip, double rclip);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnRNNGetClip(
    dpct::dnnl::engine_ext handle, dpct::dnnl::rnn_desc rnnDesc,
    cudnnRNNClipMode_t *clipMode,
    /*
    DPCT1082:23: Migration of cudnnNanPropagation_t type is not supported.
    */
    cudnnNanPropagation_t *clipNanOpt, double *lclip, double *rclip);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnSetRNNProjectionLayers(
    dpct::dnnl::engine_ext handle, dpct::dnnl::rnn_desc rnnDesc,
    const int recProjSize, const int outProjSize);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnGetRNNProjectionLayers(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    int *recProjSize, int *outProjSize);

/* Expensive. Creates the plan for the specific settings. */
CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnCreatePersistentRNNPlan(
    dpct::dnnl::rnn_desc rnnDesc, const int minibatch,
    const dpct::library_data_t dataType, cudnnPersistentRNNPlan_t *plan);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI
cudnnDestroyPersistentRNNPlan(cudnnPersistentRNNPlan_t plan);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnSetPersistentRNNPlan(
    dpct::dnnl::rnn_desc rnnDesc, cudnnPersistentRNNPlan_t plan);

dpct::err1 CUDNNWINAPI cudnnBuildRNNDynamic(dpct::dnnl::engine_ext handle,
                                            dpct::dnnl::rnn_desc rnnDesc,
                                            int miniBatch);

/* dataType in weight descriptors and input descriptors is used to describe storage */
CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnGetRNNWorkspaceSize(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const int seqLength, const dpct::dnnl::memory_desc_ext *xDesc,
    size_t *sizeInBytes);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnGetRNNTrainingReserveSize(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const int seqLength, const dpct::dnnl::memory_desc_ext *xDesc,
    size_t *sizeInBytes);

dpct::err1 CUDNNWINAPI cudnnGetRNNTempSpaceSizes(
    dpct::dnnl::engine_ext handle, dpct::dnnl::rnn_desc rnnDesc,
    dnnl::prop_kind fMode, dpct::dnnl::memory_desc_ext xDesc,
    size_t *workSpaceSize, size_t *reserveSpaceSize);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnGetRNNParamsSize(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const dpct::dnnl::memory_desc_ext xDesc, size_t *sizeInBytes,
    dpct::library_data_t dataType);

dpct::err1 CUDNNWINAPI cudnnGetRNNWeightSpaceSize(dpct::dnnl::engine_ext handle,
                                                  dpct::dnnl::rnn_desc rnnDesc,
                                                  size_t *weightSpaceSize);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnGetRNNLinLayerMatrixParams(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const int pseudoLayer, const dpct::dnnl::memory_desc_ext xDesc,
    const dpct::dnnl::memory_desc_ext wDesc, const void *w,
    const int linLayerID, dpct::dnnl::memory_desc_ext linLayerMatDesc,
    void **linLayerMat);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnGetRNNLinLayerBiasParams(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const int pseudoLayer, const dpct::dnnl::memory_desc_ext xDesc,
    const dpct::dnnl::memory_desc_ext wDesc, const void *w,
    const int linLayerID, dpct::dnnl::memory_desc_ext linLayerBiasDesc,
    void **linLayerBias);

dpct::err1 CUDNNWINAPI cudnnGetRNNWeightParams(
    dpct::dnnl::engine_ext handle, dpct::dnnl::rnn_desc rnnDesc,
    int32_t pseudoLayer, size_t weightSpaceSize, const void *weightSpace,
    int32_t linLayerID, dpct::dnnl::memory_desc_ext mDesc, void **mAddr,
    dpct::dnnl::memory_desc_ext bDesc, void **bAddr);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnRNNForwardInference(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const int seqLength, const dpct::dnnl::memory_desc_ext *xDesc,
    const void *x, const dpct::dnnl::memory_desc_ext hxDesc, const void *hx,
    const dpct::dnnl::memory_desc_ext cxDesc, const void *cx,
    const dpct::dnnl::memory_desc_ext wDesc, const void *w,
    const dpct::dnnl::memory_desc_ext *yDesc, void *y,
    const dpct::dnnl::memory_desc_ext hyDesc, void *hy,
    const dpct::dnnl::memory_desc_ext cyDesc, void *cy, void *workSpace,
    size_t workSpaceSizeInBytes);

/* RNN EX API */

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI
cudnnSetRNNPaddingMode(dpct::dnnl::rnn_desc rnnDesc, unsigned paddingMode);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI
cudnnGetRNNPaddingMode(dpct::dnnl::rnn_desc rnnDesc, unsigned *paddingMode);

dpct::err1 CUDNNWINAPI
cudnnCreateRNNDataDescriptor(dpct::dnnl::memory_desc_ext *rnnDataDesc);

dpct::err1 CUDNNWINAPI
cudnnDestroyRNNDataDescriptor(dpct::dnnl::memory_desc_ext rnnDataDesc);

dpct::err1 CUDNNWINAPI cudnnSetRNNDataDescriptor(
    dpct::dnnl::memory_desc_ext rnnDataDesc, dpct::library_data_t dataType,
    dpct::dnnl::rnn_memory_format_tag layout, int maxSeqLength, int batchSize,
    int vectorSize,
    const int seqLengthArray[], /* length of each sequence in the batch */
    void *paddingFill); /* symbol for filling padding position in output */

dpct::err1 CUDNNWINAPI cudnnGetRNNDataDescriptor(
    dpct::dnnl::memory_desc_ext rnnDataDesc, dpct::library_data_t *dataType,
    dpct::dnnl::rnn_memory_format_tag *layout, int *maxSeqLength,
    int *batchSize, int *vectorSize, int arrayLengthRequested,
    int seqLengthArray[], void *paddingFill);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnRNNForwardInferenceEx(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const dpct::dnnl::memory_desc_ext xDesc, const void *x,
    const dpct::dnnl::memory_desc_ext hxDesc, const void *hx,
    const dpct::dnnl::memory_desc_ext cxDesc, const void *cx,
    const dpct::dnnl::memory_desc_ext wDesc, const void *w,
    const dpct::dnnl::memory_desc_ext yDesc, void *y,
    const dpct::dnnl::memory_desc_ext hyDesc, void *hy,
    const dpct::dnnl::memory_desc_ext cyDesc, void *cy,
    const dpct::dnnl::memory_desc_ext kDesc, /* reserved, should pass NULL */
    const void *keys,                        /* reserved, should pass NULL */
    const dpct::dnnl::memory_desc_ext cDesc, /* reserved, should pass NULL */
    void *cAttn,                             /* reserved, should pass NULL */
    const dpct::dnnl::memory_desc_ext iDesc, /* reserved, should pass NULL */
    void *iAttn,                             /* reserved, should pass NULL */
    const dpct::dnnl::memory_desc_ext qDesc, /* reserved, should pass NULL */
    void *queries,                           /* reserved, should pass NULL */
    void *workSpace, size_t workSpaceSizeInBytes);

dpct::err1 CUDNNWINAPI cudnnRNNForward(
    dpct::dnnl::engine_ext handle, dpct::dnnl::rnn_desc rnnDesc,
    dnnl::prop_kind fwdMode, const int32_t devSeqLengths[],
    dpct::dnnl::memory_desc_ext xDesc, const void *x,
    dpct::dnnl::memory_desc_ext yDesc, void *y,
    dpct::dnnl::memory_desc_ext hDesc, const void *hx, void *hy,
    dpct::dnnl::memory_desc_ext cDesc, const void *cx, void *cy,
    size_t weightSpaceSize, const void *weightSpace, size_t workSpaceSize,
    void *workSpace, size_t reserveSpaceSize, void *reserveSpace);

/* RNN FIND API */

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnSetRNNAlgorithmDescriptor(
    dpct::dnnl::engine_ext handle, dpct::dnnl::rnn_desc rnnDesc,
    cudnnAlgorithmDescriptor_t algoDesc);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI
cudnnGetRNNForwardInferenceAlgorithmMaxCount(dpct::dnnl::engine_ext handle,
                                             const dpct::dnnl::rnn_desc rnnDesc,
                                             int *count);

CUDNN_DEPRECATED dpct::err1 CUDNNWINAPI cudnnFindRNNForwardInferenceAlgorithmEx(
    dpct::dnnl::engine_ext handle, const dpct::dnnl::rnn_desc rnnDesc,
    const int seqLength, const dpct::dnnl::memory_desc_ext *xDesc,
    const void *x, const dpct::dnnl::memory_desc_ext hxDesc, const void *hx,
    const dpct::dnnl::memory_desc_ext cxDesc, const void *cx,
    const dpct::dnnl::memory_desc_ext wDesc, const void *w,
    const dpct::dnnl::memory_desc_ext *yDesc, void *y,
    const dpct::dnnl::memory_desc_ext hyDesc, void *hy,
    const dpct::dnnl::memory_desc_ext cyDesc, void *cy,
    const float findIntensity, const int requestedAlgoCount,
    int *returnedAlgoCount, cudnnAlgorithmPerformance_t *perfResults,
    void *workspace, size_t workSpaceSizeInBytes);

/* Sequence data descriptor */

typedef enum {
    CUDNN_SEQDATA_TIME_DIM  = 0, /* index in time */
    CUDNN_SEQDATA_BATCH_DIM = 1, /* index in batch */
    CUDNN_SEQDATA_BEAM_DIM  = 2, /* index in beam */
    CUDNN_SEQDATA_VECT_DIM  = 3  /* index in vector */
} cudnnSeqDataAxis_t;

struct cudnnSeqDataStruct;
typedef struct cudnnSeqDataStruct *cudnnSeqDataDescriptor_t;

#define CUDNN_SEQDATA_DIM_COUNT 4 /* dimension count */

dpct::err1 CUDNNWINAPI
cudnnCreateSeqDataDescriptor(cudnnSeqDataDescriptor_t *seqDataDesc);

dpct::err1 CUDNNWINAPI
cudnnDestroySeqDataDescriptor(cudnnSeqDataDescriptor_t seqDataDesc);

dpct::err1 CUDNNWINAPI cudnnSetSeqDataDescriptor(
    cudnnSeqDataDescriptor_t seqDataDesc, dpct::library_data_t dataType,
    int nbDims, const int dimA[], const cudnnSeqDataAxis_t axes[],
    size_t seqLengthArraySize, const int seqLengthArray[], void *paddingFill);

dpct::err1 CUDNNWINAPI cudnnGetSeqDataDescriptor(
    const cudnnSeqDataDescriptor_t seqDataDesc, dpct::library_data_t *dataType,
    int *nbDims, int nbDimsRequested, int dimA[], cudnnSeqDataAxis_t axes[],
    size_t *seqLengthArraySize, size_t seqLengthSizeRequested,
    int seqLengthArray[], void *paddingFill);

/* Multihead Attention */

/* Legacy type for backward compatibility */
typedef unsigned cudnnAttnQueryMap_t;

/*
 * Multi-head attention options passed via 'attnMode' in cudnnSetAttnDescriptor().
 * Use the bitwise OR operator to combine several settings listed below.  Additional
 * minor options can be added here w/o changing or introducing new API functions.
 */
#define CUDNN_ATTN_QUERYMAP_ALL_TO_ONE 0         /* multiple Q-s map to a single (K,V) set when beam size > 1 */
#define CUDNN_ATTN_QUERYMAP_ONE_TO_ONE (1U << 0) /* multiple Q-s map to multiple (K,V) sets when beam size > 1 */
#define CUDNN_ATTN_DISABLE_PROJ_BIASES 0         /* no biases in attention input and output projections */
#define CUDNN_ATTN_ENABLE_PROJ_BIASES (1U << 1)  /* use biases in attention input and output projections */

struct cudnnAttnStruct;
typedef struct cudnnAttnStruct *cudnnAttnDescriptor_t;

dpct::err1 CUDNNWINAPI
cudnnCreateAttnDescriptor(cudnnAttnDescriptor_t *attnDesc);

dpct::err1 CUDNNWINAPI
cudnnDestroyAttnDescriptor(cudnnAttnDescriptor_t attnDesc);

dpct::err1 CUDNNWINAPI cudnnSetAttnDescriptor(
    cudnnAttnDescriptor_t attnDesc, unsigned attnMode, int nHeads,
    double smScaler, dpct::library_data_t dataType,
    dpct::library_data_t computePrec, cudnnMathType_t mathType,
    cudnnDropoutDescriptor_t attnDropoutDesc,
    cudnnDropoutDescriptor_t postDropoutDesc, int qSize, int kSize, int vSize,
    int qProjSize, int kProjSize, int vProjSize, int oProjSize,
    int qoMaxSeqLength, int kvMaxSeqLength, int maxBatchSize, int maxBeamSize);

dpct::err1 CUDNNWINAPI cudnnGetAttnDescriptor(
    cudnnAttnDescriptor_t attnDesc, unsigned *attnMode, int *nHeads,
    double *smScaler, dpct::library_data_t *dataType,
    dpct::library_data_t *computePrec, cudnnMathType_t *mathType,
    cudnnDropoutDescriptor_t *attnDropoutDesc,
    cudnnDropoutDescriptor_t *postDropoutDesc, int *qSize, int *kSize,
    int *vSize, int *qProjSize, int *kProjSize, int *vProjSize, int *oProjSize,
    int *qoMaxSeqLength, int *kvMaxSeqLength, int *maxBatchSize,
    int *maxBeamSize);

dpct::err1 CUDNNWINAPI cudnnGetMultiHeadAttnBuffers(
    dpct::dnnl::engine_ext handle, const cudnnAttnDescriptor_t attnDesc,
    size_t *weightSizeInBytes, size_t *workSpaceSizeInBytes,
    size_t *reserveSpaceSizeInBytes);

typedef enum {
    CUDNN_MH_ATTN_Q_WEIGHTS = 0, /* input projection weights for 'queries' */
    CUDNN_MH_ATTN_K_WEIGHTS = 1, /* input projection weights for 'keys' */
    CUDNN_MH_ATTN_V_WEIGHTS = 2, /* input projection weights for 'values' */
    CUDNN_MH_ATTN_O_WEIGHTS = 3, /* output projection weights */
    CUDNN_MH_ATTN_Q_BIASES  = 4, /* input projection bias tensor for 'queries' */
    CUDNN_MH_ATTN_K_BIASES  = 5, /* input projection bias for 'keys' */
    CUDNN_MH_ATTN_V_BIASES  = 6, /* input projection bias for 'values' */
    CUDNN_MH_ATTN_O_BIASES  = 7, /* output projection biases */
} cudnnMultiHeadAttnWeightKind_t;

#define CUDNN_ATTN_WKIND_COUNT 8 /* Number of attention weight/bias tensors */

dpct::err1 CUDNNWINAPI cudnnGetMultiHeadAttnWeights(
    dpct::dnnl::engine_ext handle, const cudnnAttnDescriptor_t attnDesc,
    cudnnMultiHeadAttnWeightKind_t wKind, size_t weightSizeInBytes,
    const void *weights, dpct::dnnl::memory_desc_ext wDesc, void **wAddr);

dpct::err1 CUDNNWINAPI cudnnMultiHeadAttnForward(
    dpct::dnnl::engine_ext handle, const cudnnAttnDescriptor_t attnDesc,
    int currIdx, const int loWinIdx[], const int hiWinIdx[],
    const int devSeqLengthsQO[], const int devSeqLengthsKV[],
    const cudnnSeqDataDescriptor_t qDesc, const void *queries,
    const void *residuals, const cudnnSeqDataDescriptor_t kDesc,
    const void *keys, const cudnnSeqDataDescriptor_t vDesc, const void *values,
    const cudnnSeqDataDescriptor_t oDesc, void *out, size_t weightSizeInBytes,
    const void *weights, size_t workSpaceSizeInBytes, void *workSpace,
    size_t reserveSpaceSizeInBytes, void *reserveSpace);

/*
 * \brief Cross-library version checker.
 * This function is implemented differently in each sub-library. Each sublib
 * checks whether its own version matches that of its dependencies.
 * \returns CUDNN_STATUS_SUCCESS if the version check passes,
 *          CUDNN_STATUS_VERSION_MISMATCH if the versions are inconsistent.
 */
dpct::err1 CUDNNWINAPI cudnnAdvInferVersionCheck(void);

#if defined(__cplusplus)
}
#endif

#endif /* CUDNN_ADV_INFER_H_ */
